#### Import the required libraries

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.cluster import KMeans

#### Read the data

Load the csv file and print the first five observations.

df = pd.read_csv("wholesale_cust.csv")
df.head()

df.shape

df.isnull().sum()

**The data definition is as follows:** 

**Region**:  City of the retailer

**Vegetables**: Annual spending on vegetables

**Personal_care**: Annual spending on personal care products

**Milk**: Annual spending on milk and milk products

**Grocery**: Annual spending on grocery

**Plasticware**: Annual spending on plasticware (container, bottles, dishes and so on)

### Let's begin with some hands-on practice exercises



df[df.duplicated()]

df[(df['Region'] == 'Rochester')& (df['Vegetables'] == 22620)]

df.drop_duplicates(inplace=True)

df[df.duplicated()]

df.shape



df['Region'].value_counts()

sns.countplot(data=df,x='Region')
plt.xlabel('Region')
plt.ylabel('Count_of_observations')
plt.show()


fig,ax = plt.subplots(2,3,figsize=(15,10))
for col,subplot in zip(df.select_dtypes(include=np.number).columns,ax.flatten()):
    sns.boxplot(df[col],ax=subplot)
    subplot.set_title(col)  
plt.show()



#num_df = df.select_dtypes(include=np.number)
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)

IQR = Q3-Q1

upper_limit = Q3 + 3 * IQR
o_df= df[~(df>upper_limit).any(axis=1)]

o_df

o_df.isnull().sum()

fig,ax = plt.subplots(2,3,figsize=(15,10))
for col,subplot in zip(o_df.select_dtypes(include=np.number).columns,ax.flatten()):
    sns.boxplot(o_df[col],ax=subplot)
    subplot.set_title(col)  
plt.show()



from sklearn.preprocessing import PowerTransformer,StandardScaler

# pt = PowerTransformer()
# transfomed_data = pt.fit_transform(o_df[o_df.select_dtypes(include=np.number).columns])

ss = StandardScaler()
scaled_data = ss.fit_transform(o_df[o_df.select_dtypes(include=np.number).columns])
scaled_data =pd.DataFrame(data=scaled_data,columns=o_df.select_dtypes(include=np.number).columns)

scaled_data



from sklearn.metrics import silhouette_score

!pip install yellowbricks

from yellowbrick.cluster import SilhouetteVisualizer

from sklearn.cluster import KMeans



for i in range(2,5):
    model = KMeans(n_clusters = i,random_state = 1)
    model.fit(scaled_data)
    sv = SilhouetteVisualizer(model)
    sv.fit(scaled_data)
    plt.show()


model = KMeans(n_clusters = 2,random_state = 1)
model.fit(scaled_data)

o_df['labels']=model.labels_

sns.scatterplot(data=o_df,x='Vegetables',y='Personal_care',hue='labels')


Vegetables: Annual spending on vegetables

Personal_care: Annual spending on personal care products

person spends higher on vegetables annually doesnt spend much on personal care and vice versa



Oneonta_df = o_df[o_df['Region']=='Oneonta']

Oneonta_df

err =[]
for i in range(1,6):
    model = KMeans(n_clusters = i,random_state = 1)
    model.fit(scaled_data)
    err.append(model.inertia_)

err

plt.plot(range(1,6),err,marker='*')
plt.show()



when cluster =2

ss = StandardScaler()
scaled_data_OneOnta = ss.fit_transform(Oneonta_df[Oneonta_df.select_dtypes(include=np.number).columns])
scaled_data_OneOnta =pd.DataFrame(data=scaled_data_OneOnta,columns=Oneonta_df.select_dtypes(include=np.number).columns)

err =[]
for i in range(1,6):
    model = KMeans(n_clusters = i,random_state = 1)
    model.fit(scaled_data_OneOnta)
    err.append(model.inertia_)

Oneonta_df['labels']=model.labels_

Oneonta_df

Oneonta_df['labels'].value_counts()
